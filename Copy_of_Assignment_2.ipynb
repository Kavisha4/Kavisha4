{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kavisha4/Kavisha4/blob/main/Copy_of_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP6JLo1tGNBg"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWZyYmS_UE_L"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxkJoQBkUIHC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaTwK7ojXr2F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12fb3b13-8e38-48f9-f7f0-1ef8596c7875"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E0Q3aoKUCRX"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKWAkFVGUU0Z"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXUkhkMfU4wq"
      },
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYP9cQTWbzuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f3fb139-ef9f-46cb-c45e-92606c39c50a"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38vKGE6Nb2RR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e8a59b-e070-4351-991c-927dc5936624"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "aLv7t1AhSSfh",
        "outputId": "aa13a708-6151-40e8-d44a-b8d90dddb417"
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>15574012</td>\n",
              "      <td>Chu</td>\n",
              "      <td>645</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>44</td>\n",
              "      <td>8</td>\n",
              "      <td>113755.78</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>149756.71</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>15592531</td>\n",
              "      <td>Bartlett</td>\n",
              "      <td>822</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>50</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10062.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>15656148</td>\n",
              "      <td>Obinna</td>\n",
              "      <td>376</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Female</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>115046.74</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>119346.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>15792365</td>\n",
              "      <td>He</td>\n",
              "      <td>501</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>44</td>\n",
              "      <td>4</td>\n",
              "      <td>142051.07</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>74940.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>15592389</td>\n",
              "      <td>H?</td>\n",
              "      <td>684</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>134603.88</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>71725.73</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "5          6    15574012       Chu  ...               0       149756.71      1\n",
              "6          7    15592531  Bartlett  ...               1        10062.80      0\n",
              "7          8    15656148    Obinna  ...               0       119346.88      1\n",
              "8          9    15792365        He  ...               1        74940.50      0\n",
              "9         10    15592389        H?  ...               1        71725.73      0\n",
              "\n",
              "[10 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6bQ0UgSU-NJ"
      },
      "source": [
        "### Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le5MJreAbW52"
      },
      "source": [
        "Label Encoding the \"Gender\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxVKWXxLbczC"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X[:, 2] = le.fit_transform(X[:, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M1KboxFb6OO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd7705a-20c5-4231-c9a9-905be5403049"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[619 'France' 0 ... 1 1 101348.88]\n",
            " [608 'Spain' 0 ... 0 1 112542.58]\n",
            " [502 'France' 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 0 ... 0 1 42085.58]\n",
            " [772 'Germany' 1 ... 1 0 92888.52]\n",
            " [792 'France' 0 ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68ry8-RQOqFf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUxGZezpbMcb"
      },
      "source": [
        "One Hot Encoding the \"Geography\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMXC8-KMVirw"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcxwEon-b8nV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a60ef07-711c-440a-c40b-12e1712db523"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
            " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
            " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
            " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQMGcJEvTGkP",
        "outputId": "04ee9ff5-7941-4bbb-b995-043c5ec287e1"
      },
      "source": [
        "print(X[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0 0.0 0.0 619 0 42 2 0.0 1 1 1 101348.88]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHQWWD89TGs7",
        "outputId": "8b72b660-3b47-4d05-aefa-d6f2c5df6832"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHol938cW8zd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-TDt0Y_XEfc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE_FcHyfV3TQ"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViCrE00rV8Sk"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad7ZM3_jT3BU",
        "outputId": "85a6e763-bf0c-45db-c0de-d7ce75b1bed5"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.01460667 -0.5698444   1.74309049  0.16958176 -1.09168714 -0.46460796\n",
            "  0.00666099 -1.21571749  0.8095029   0.64259497 -1.03227043  1.10643166]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zfEzkRVXIwF"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvdeScabXtlB"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dtrScHxXQox"
      },
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP6urV6SX7kS"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bppGycBXYCQr"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BELWAc_8YJze"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JneR0u0sYRTd"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyNEe6RXYcU4"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3x41RBYfvY"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT4u2S1_Y4WG"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GWlJChhY_ZI"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG3RrwDXZEaS"
      },
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QR_G5u7ZLSM"
      },
      "source": [
        "### Training the ANN on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHZ-LKv_ZRb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6b38e4-bbc2-40d0-abef-026078f60769"
      },
      "source": [
        "#train on 100,500,1000 epochs\n",
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "250/250 [==============================] - 1s 1ms/step - loss: 0.6205 - accuracy: 0.6850\n",
            "Epoch 2/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7960\n",
            "Epoch 3/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7960\n",
            "Epoch 4/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.8016\n",
            "Epoch 5/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.8151\n",
            "Epoch 6/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4190 - accuracy: 0.8240\n",
            "Epoch 7/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.8278\n",
            "Epoch 8/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4045 - accuracy: 0.8311\n",
            "Epoch 9/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3984 - accuracy: 0.8331\n",
            "Epoch 10/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3924 - accuracy: 0.8356\n",
            "Epoch 11/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3854 - accuracy: 0.8409\n",
            "Epoch 12/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.8446\n",
            "Epoch 13/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8475\n",
            "Epoch 14/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3656 - accuracy: 0.8497\n",
            "Epoch 15/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8525\n",
            "Epoch 16/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3570 - accuracy: 0.8544\n",
            "Epoch 17/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.8574\n",
            "Epoch 18/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3517 - accuracy: 0.8553\n",
            "Epoch 19/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3492 - accuracy: 0.8575\n",
            "Epoch 20/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8597\n",
            "Epoch 21/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 0.8591\n",
            "Epoch 22/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.8609\n",
            "Epoch 23/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3434 - accuracy: 0.8597\n",
            "Epoch 24/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8596\n",
            "Epoch 25/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8619\n",
            "Epoch 26/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3413 - accuracy: 0.8626\n",
            "Epoch 27/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8612\n",
            "Epoch 28/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8618\n",
            "Epoch 29/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8610\n",
            "Epoch 30/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8620\n",
            "Epoch 31/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8622\n",
            "Epoch 32/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8619\n",
            "Epoch 33/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8622\n",
            "Epoch 34/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8640\n",
            "Epoch 35/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8625\n",
            "Epoch 36/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8630\n",
            "Epoch 37/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8625\n",
            "Epoch 38/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8631\n",
            "Epoch 39/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8643\n",
            "Epoch 40/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8641\n",
            "Epoch 41/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8637\n",
            "Epoch 42/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8643\n",
            "Epoch 43/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8633\n",
            "Epoch 44/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8643\n",
            "Epoch 45/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8639\n",
            "Epoch 46/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8660\n",
            "Epoch 47/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8644\n",
            "Epoch 48/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8654\n",
            "Epoch 49/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8644\n",
            "Epoch 50/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8649\n",
            "Epoch 51/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8652\n",
            "Epoch 52/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8652\n",
            "Epoch 53/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8640\n",
            "Epoch 54/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8659\n",
            "Epoch 55/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8645\n",
            "Epoch 56/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8656\n",
            "Epoch 57/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8635\n",
            "Epoch 58/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8643\n",
            "Epoch 59/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8637\n",
            "Epoch 60/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8634\n",
            "Epoch 61/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8649\n",
            "Epoch 62/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8634\n",
            "Epoch 63/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8633\n",
            "Epoch 64/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8654\n",
            "Epoch 65/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8641\n",
            "Epoch 66/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8640\n",
            "Epoch 67/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8627\n",
            "Epoch 68/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8639\n",
            "Epoch 69/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8637\n",
            "Epoch 70/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8630\n",
            "Epoch 71/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8644\n",
            "Epoch 72/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8645\n",
            "Epoch 73/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8627\n",
            "Epoch 74/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8626\n",
            "Epoch 75/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8633\n",
            "Epoch 76/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8643\n",
            "Epoch 77/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8643\n",
            "Epoch 78/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8651\n",
            "Epoch 79/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8645\n",
            "Epoch 80/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8640\n",
            "Epoch 81/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8640\n",
            "Epoch 82/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8645\n",
            "Epoch 83/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8641\n",
            "Epoch 84/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8636\n",
            "Epoch 85/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8636\n",
            "Epoch 86/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8652\n",
            "Epoch 87/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8636\n",
            "Epoch 88/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8646\n",
            "Epoch 89/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8641\n",
            "Epoch 90/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8626\n",
            "Epoch 91/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8644\n",
            "Epoch 92/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8639\n",
            "Epoch 93/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8641\n",
            "Epoch 94/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8629\n",
            "Epoch 95/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8643\n",
            "Epoch 96/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8640\n",
            "Epoch 97/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8627\n",
            "Epoch 98/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8652\n",
            "Epoch 99/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8639\n",
            "Epoch 100/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8637\n",
            "Epoch 101/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8630\n",
            "Epoch 102/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8644\n",
            "Epoch 103/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8641\n",
            "Epoch 104/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8651\n",
            "Epoch 105/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8639\n",
            "Epoch 106/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8643\n",
            "Epoch 107/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8641\n",
            "Epoch 108/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8640\n",
            "Epoch 109/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8644\n",
            "Epoch 110/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8645\n",
            "Epoch 111/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8644\n",
            "Epoch 112/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8634\n",
            "Epoch 113/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8656\n",
            "Epoch 114/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8645\n",
            "Epoch 115/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8634\n",
            "Epoch 116/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8646\n",
            "Epoch 117/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8650\n",
            "Epoch 118/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8645\n",
            "Epoch 119/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8646\n",
            "Epoch 120/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8655\n",
            "Epoch 121/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8652\n",
            "Epoch 122/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8645\n",
            "Epoch 123/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8630\n",
            "Epoch 124/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8649\n",
            "Epoch 125/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8654\n",
            "Epoch 126/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8651\n",
            "Epoch 127/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8637\n",
            "Epoch 128/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8659\n",
            "Epoch 129/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8650\n",
            "Epoch 130/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8639\n",
            "Epoch 131/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8654\n",
            "Epoch 132/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8651\n",
            "Epoch 133/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8660\n",
            "Epoch 134/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8639\n",
            "Epoch 135/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8635\n",
            "Epoch 136/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8654\n",
            "Epoch 137/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8648\n",
            "Epoch 138/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8629\n",
            "Epoch 139/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8622\n",
            "Epoch 140/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8631\n",
            "Epoch 141/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8651\n",
            "Epoch 142/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8646\n",
            "Epoch 143/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8631\n",
            "Epoch 144/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8645\n",
            "Epoch 145/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8639\n",
            "Epoch 146/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8640\n",
            "Epoch 147/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8662\n",
            "Epoch 148/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8634\n",
            "Epoch 149/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8649\n",
            "Epoch 150/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8658\n",
            "Epoch 151/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8645\n",
            "Epoch 152/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8656\n",
            "Epoch 153/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8645\n",
            "Epoch 154/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8641\n",
            "Epoch 155/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8650\n",
            "Epoch 156/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8644\n",
            "Epoch 157/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8650\n",
            "Epoch 158/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8664\n",
            "Epoch 159/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8646\n",
            "Epoch 160/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8649\n",
            "Epoch 161/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8654\n",
            "Epoch 162/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8654\n",
            "Epoch 163/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8639\n",
            "Epoch 164/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8640\n",
            "Epoch 165/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8635\n",
            "Epoch 166/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8648\n",
            "Epoch 167/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8641\n",
            "Epoch 168/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8664\n",
            "Epoch 169/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8627\n",
            "Epoch 170/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8649\n",
            "Epoch 171/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8646\n",
            "Epoch 172/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8636\n",
            "Epoch 173/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8641\n",
            "Epoch 174/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8630\n",
            "Epoch 175/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8640\n",
            "Epoch 176/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8639\n",
            "Epoch 177/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8640\n",
            "Epoch 178/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8641\n",
            "Epoch 179/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8646\n",
            "Epoch 180/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8649\n",
            "Epoch 181/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8634\n",
            "Epoch 182/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8660\n",
            "Epoch 183/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8643\n",
            "Epoch 184/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8664\n",
            "Epoch 185/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8635\n",
            "Epoch 186/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8645\n",
            "Epoch 187/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8649\n",
            "Epoch 188/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8633\n",
            "Epoch 189/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8654\n",
            "Epoch 190/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8635\n",
            "Epoch 191/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8641\n",
            "Epoch 192/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8639\n",
            "Epoch 193/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8639\n",
            "Epoch 194/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8636\n",
            "Epoch 195/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8651\n",
            "Epoch 196/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8643\n",
            "Epoch 197/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8648\n",
            "Epoch 198/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8631\n",
            "Epoch 199/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8648\n",
            "Epoch 200/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8651\n",
            "Epoch 201/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8645\n",
            "Epoch 202/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8651\n",
            "Epoch 203/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8636\n",
            "Epoch 204/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8636\n",
            "Epoch 205/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8651\n",
            "Epoch 206/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8640\n",
            "Epoch 207/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8636\n",
            "Epoch 208/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8639\n",
            "Epoch 209/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8629\n",
            "Epoch 210/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8629\n",
            "Epoch 211/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8652\n",
            "Epoch 212/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8641\n",
            "Epoch 213/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8637\n",
            "Epoch 214/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8649\n",
            "Epoch 215/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8646\n",
            "Epoch 216/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8635\n",
            "Epoch 217/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8644\n",
            "Epoch 218/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8635\n",
            "Epoch 219/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8641\n",
            "Epoch 220/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8656\n",
            "Epoch 221/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8649\n",
            "Epoch 222/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8635\n",
            "Epoch 223/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8630\n",
            "Epoch 224/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8631\n",
            "Epoch 225/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8648\n",
            "Epoch 226/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8660\n",
            "Epoch 227/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8649\n",
            "Epoch 228/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8644\n",
            "Epoch 229/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8634\n",
            "Epoch 230/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8646\n",
            "Epoch 231/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8645\n",
            "Epoch 232/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8644\n",
            "Epoch 233/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8639\n",
            "Epoch 234/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8644\n",
            "Epoch 235/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8641\n",
            "Epoch 236/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8645\n",
            "Epoch 237/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8650\n",
            "Epoch 238/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8648\n",
            "Epoch 239/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8641\n",
            "Epoch 240/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8652\n",
            "Epoch 241/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8634\n",
            "Epoch 242/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8639\n",
            "Epoch 243/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8646\n",
            "Epoch 244/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8641\n",
            "Epoch 245/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8646\n",
            "Epoch 246/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8644\n",
            "Epoch 247/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8649\n",
            "Epoch 248/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8639\n",
            "Epoch 249/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8650\n",
            "Epoch 250/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8649\n",
            "Epoch 251/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8646\n",
            "Epoch 252/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8646\n",
            "Epoch 253/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8629\n",
            "Epoch 254/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8645\n",
            "Epoch 255/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8646\n",
            "Epoch 256/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8640\n",
            "Epoch 257/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8650\n",
            "Epoch 258/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8636\n",
            "Epoch 259/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8656\n",
            "Epoch 260/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8636\n",
            "Epoch 261/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8660\n",
            "Epoch 262/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8651\n",
            "Epoch 263/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8643\n",
            "Epoch 264/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8644\n",
            "Epoch 265/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8635\n",
            "Epoch 266/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8633\n",
            "Epoch 267/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8637\n",
            "Epoch 268/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8644\n",
            "Epoch 269/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8645\n",
            "Epoch 270/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8629\n",
            "Epoch 271/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8649\n",
            "Epoch 272/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8636\n",
            "Epoch 273/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8671\n",
            "Epoch 274/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8654\n",
            "Epoch 275/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8624\n",
            "Epoch 276/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8635\n",
            "Epoch 277/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8626\n",
            "Epoch 278/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8629\n",
            "Epoch 279/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8648\n",
            "Epoch 280/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8631\n",
            "Epoch 281/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8631\n",
            "Epoch 282/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8634\n",
            "Epoch 283/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8643\n",
            "Epoch 284/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8648\n",
            "Epoch 285/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8641\n",
            "Epoch 286/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8643\n",
            "Epoch 287/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8645\n",
            "Epoch 288/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8641\n",
            "Epoch 289/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8655\n",
            "Epoch 290/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8636\n",
            "Epoch 291/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8643\n",
            "Epoch 292/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8644\n",
            "Epoch 293/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8620\n",
            "Epoch 294/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8659\n",
            "Epoch 295/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8656\n",
            "Epoch 296/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8626\n",
            "Epoch 297/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8645\n",
            "Epoch 298/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8645\n",
            "Epoch 299/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8649\n",
            "Epoch 300/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8633\n",
            "Epoch 301/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8648\n",
            "Epoch 302/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8648\n",
            "Epoch 303/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8634\n",
            "Epoch 304/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8640\n",
            "Epoch 305/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8655\n",
            "Epoch 306/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8646\n",
            "Epoch 307/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8652\n",
            "Epoch 308/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8650\n",
            "Epoch 309/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8650\n",
            "Epoch 310/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8651\n",
            "Epoch 311/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8627\n",
            "Epoch 312/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8634\n",
            "Epoch 313/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8644\n",
            "Epoch 314/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8630\n",
            "Epoch 315/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8654\n",
            "Epoch 316/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8639\n",
            "Epoch 317/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8643\n",
            "Epoch 318/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8654\n",
            "Epoch 319/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8648\n",
            "Epoch 320/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8631\n",
            "Epoch 321/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8650\n",
            "Epoch 322/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8633\n",
            "Epoch 323/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8615\n",
            "Epoch 324/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8645\n",
            "Epoch 325/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8651\n",
            "Epoch 326/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8646\n",
            "Epoch 327/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8626\n",
            "Epoch 328/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8641\n",
            "Epoch 329/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8659\n",
            "Epoch 330/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8637\n",
            "Epoch 331/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8633\n",
            "Epoch 332/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8641\n",
            "Epoch 333/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8658\n",
            "Epoch 334/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8620\n",
            "Epoch 335/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8637\n",
            "Epoch 336/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8630\n",
            "Epoch 337/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8649\n",
            "Epoch 338/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8646\n",
            "Epoch 339/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8646\n",
            "Epoch 340/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8625\n",
            "Epoch 341/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8651\n",
            "Epoch 342/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8630\n",
            "Epoch 343/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8627\n",
            "Epoch 344/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8629\n",
            "Epoch 345/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8644\n",
            "Epoch 346/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8634\n",
            "Epoch 347/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8635\n",
            "Epoch 348/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8649\n",
            "Epoch 349/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8630\n",
            "Epoch 350/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8648\n",
            "Epoch 351/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8627\n",
            "Epoch 352/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8645\n",
            "Epoch 353/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8637\n",
            "Epoch 354/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8639\n",
            "Epoch 355/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8633\n",
            "Epoch 356/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8654\n",
            "Epoch 357/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8645\n",
            "Epoch 358/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8658\n",
            "Epoch 359/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8637\n",
            "Epoch 360/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8649\n",
            "Epoch 361/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8643\n",
            "Epoch 362/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8644\n",
            "Epoch 363/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8644\n",
            "Epoch 364/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8639\n",
            "Epoch 365/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8646\n",
            "Epoch 366/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8624\n",
            "Epoch 367/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8633\n",
            "Epoch 368/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8635\n",
            "Epoch 369/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8641\n",
            "Epoch 370/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8646\n",
            "Epoch 371/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8634\n",
            "Epoch 372/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8651\n",
            "Epoch 373/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8634\n",
            "Epoch 374/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8626\n",
            "Epoch 375/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8634\n",
            "Epoch 376/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8654\n",
            "Epoch 377/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8654\n",
            "Epoch 378/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8645\n",
            "Epoch 379/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8654\n",
            "Epoch 380/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8630\n",
            "Epoch 381/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8659\n",
            "Epoch 382/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8625\n",
            "Epoch 383/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8641\n",
            "Epoch 384/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8649\n",
            "Epoch 385/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8644\n",
            "Epoch 386/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8640\n",
            "Epoch 387/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8643\n",
            "Epoch 388/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8635\n",
            "Epoch 389/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8627\n",
            "Epoch 390/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8649\n",
            "Epoch 391/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8651\n",
            "Epoch 392/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8650\n",
            "Epoch 393/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8644\n",
            "Epoch 394/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8643\n",
            "Epoch 395/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8627\n",
            "Epoch 396/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8622\n",
            "Epoch 397/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8640\n",
            "Epoch 398/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8655\n",
            "Epoch 399/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8646\n",
            "Epoch 400/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8636\n",
            "Epoch 401/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8634\n",
            "Epoch 402/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8648\n",
            "Epoch 403/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8633\n",
            "Epoch 404/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8641\n",
            "Epoch 405/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8636\n",
            "Epoch 406/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8644\n",
            "Epoch 407/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8636\n",
            "Epoch 408/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8629\n",
            "Epoch 409/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8646\n",
            "Epoch 410/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8641\n",
            "Epoch 411/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8649\n",
            "Epoch 412/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8627\n",
            "Epoch 413/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8637\n",
            "Epoch 414/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8650\n",
            "Epoch 415/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8650\n",
            "Epoch 416/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8648\n",
            "Epoch 417/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8648\n",
            "Epoch 418/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8649\n",
            "Epoch 419/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8649\n",
            "Epoch 420/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8654\n",
            "Epoch 421/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8650\n",
            "Epoch 422/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8636\n",
            "Epoch 423/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8656\n",
            "Epoch 424/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8659\n",
            "Epoch 425/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3287 - accuracy: 0.8649\n",
            "Epoch 426/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8635\n",
            "Epoch 427/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8629\n",
            "Epoch 428/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8629\n",
            "Epoch 429/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8639\n",
            "Epoch 430/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8649\n",
            "Epoch 431/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8652\n",
            "Epoch 432/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8641\n",
            "Epoch 433/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8643\n",
            "Epoch 434/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8631\n",
            "Epoch 435/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8669\n",
            "Epoch 436/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8633\n",
            "Epoch 437/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8624\n",
            "Epoch 438/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8651\n",
            "Epoch 439/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8650\n",
            "Epoch 440/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8639\n",
            "Epoch 441/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8652\n",
            "Epoch 442/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8629\n",
            "Epoch 443/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8643\n",
            "Epoch 444/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8626\n",
            "Epoch 445/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8654\n",
            "Epoch 446/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8639\n",
            "Epoch 447/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8641\n",
            "Epoch 448/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8654\n",
            "Epoch 449/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8635\n",
            "Epoch 450/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8635\n",
            "Epoch 451/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8651\n",
            "Epoch 452/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8637\n",
            "Epoch 453/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8645\n",
            "Epoch 454/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8648\n",
            "Epoch 455/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8651\n",
            "Epoch 456/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8644\n",
            "Epoch 457/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8645\n",
            "Epoch 458/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8641\n",
            "Epoch 459/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8650\n",
            "Epoch 460/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8636\n",
            "Epoch 461/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8651\n",
            "Epoch 462/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8644\n",
            "Epoch 463/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8637\n",
            "Epoch 464/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8644\n",
            "Epoch 465/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8639\n",
            "Epoch 466/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8643\n",
            "Epoch 467/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8641\n",
            "Epoch 468/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8645\n",
            "Epoch 469/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8644\n",
            "Epoch 470/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8639\n",
            "Epoch 471/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8637\n",
            "Epoch 472/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8646\n",
            "Epoch 473/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8658\n",
            "Epoch 474/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8659\n",
            "Epoch 475/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8649\n",
            "Epoch 476/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8621\n",
            "Epoch 477/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8649\n",
            "Epoch 478/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8646\n",
            "Epoch 479/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8644\n",
            "Epoch 480/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8627\n",
            "Epoch 481/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8651\n",
            "Epoch 482/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8637\n",
            "Epoch 483/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8633\n",
            "Epoch 484/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8626\n",
            "Epoch 485/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8627\n",
            "Epoch 486/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8648\n",
            "Epoch 487/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8630\n",
            "Epoch 488/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8639\n",
            "Epoch 489/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8654\n",
            "Epoch 490/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8633\n",
            "Epoch 491/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8645\n",
            "Epoch 492/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8645\n",
            "Epoch 493/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8646\n",
            "Epoch 494/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8629\n",
            "Epoch 495/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8646\n",
            "Epoch 496/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8629\n",
            "Epoch 497/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8639\n",
            "Epoch 498/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8652\n",
            "Epoch 499/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8630\n",
            "Epoch 500/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbdbce4da50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJj5k2MxZga3"
      },
      "source": [
        "## Part 4 - Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84QFoqGYeXHL"
      },
      "source": [
        "### Predicting the result of 3 observation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGjx94g2n7OV"
      },
      "source": [
        "Therefore, our ANN model predicts that this customer stays in the bank!\n",
        "\n",
        "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
        "\n",
        "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns.For Male you should encode as '1' and for Female '0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGRo3eacgDdC"
      },
      "source": [
        "**Assignment**\n",
        "\n",
        "Use our ANN model to predict if the customers with the following informations will leave the bank: \n",
        "\n",
        "Geography: France,Germany,Spain\n",
        "\n",
        "Credit Score: 600,800,700\n",
        "\n",
        "Gender: Male,Female,Male\n",
        "\n",
        "Age: 40,50,35,years old\n",
        "\n",
        "Tenure: 3,5,4 years\n",
        "\n",
        "Balance: \\$ 60000,70000,0\n",
        "\n",
        "Number of Products: 2,1,0\n",
        "\n",
        "Does this customer have a credit card ? Yes,No,No\n",
        "\n",
        "Is this customer an Active Member: Yes,No,No\n",
        "\n",
        "Estimated Salary: \\$ 50000,10000,0\n",
        "\n",
        "So, should we say goodbye to that customer ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhU1LTgPg-kH"
      },
      "source": [
        "Sample \n",
        "If value is greater than 0.5 - True  \n",
        "Else -False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-15JL842dxWo"
      },
      "source": [
        "#print(ann.predict(sc.transform([[input your values here]])) is greater than  0.5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opk6uV7JjjW7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGAYIx4Zjjgh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCw4m5bCjkKt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7yx47jPZt11"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIyEeQdRZwgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3728428e-c441-4dd8-fac9-f54976ffedb0"
      },
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tjvfa5SBe-eP",
        "outputId": "119fa4e2-04bb-4c5e-be73-d65b447c9fcf"
      },
      "source": [
        "y_pred[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KcgCBWbX89C",
        "outputId": "75f0ae6d-3dd2-40f1-f8f9-e8a89e7ac3bc"
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0oyfLWoaEGw"
      },
      "source": [
        "### Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci6K_r6LaF6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bfc2a09-5070-46e2-8fcc-0376e0c3e941"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1516   79]\n",
            " [ 204  201]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ut3uyxlOqs",
        "outputId": "68c5f258-553c-4de0-e93b-36ce0a500484"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8585"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "qSRSEMXDjmI2",
        "outputId": "34ba6683-3eca-4a3a-fc10-328f48bba74f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "LABELS = ['Not Left Bank', 'Left Bank'] \n",
        "plt.figure(figsize =(8, 8)) \n",
        "sns.heatmap(cm, xticklabels = LABELS,  \n",
        "            yticklabels = LABELS, annot = True, fmt =\"d\"); \n",
        "plt.title(\"Confusion matrix\") \n",
        "plt.ylabel('True class') \n",
        "plt.xlabel('Predicted class') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ijy_fUxk-Ga",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "26477fc3-0613-4260-fc5e-2278c3dc87c7"
      },
      "source": [
        "print(ann.predict(sc.transform([1,0,0,600,1,40,3,60000,2,1,1,50000,0]])))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-64-8effba177757>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print(ann.predict(sc.transform([1,0,0,600,1,40,3,60000,2,1,1,50000,0]])))\u001b[0m\n\u001b[0m                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}